{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOMBkrLoEhxy",
        "outputId": "261d32c0-855f-458d-e3b6-6a180b34b99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.11.12)\n",
            "\n",
            "==============================\n",
            "üìå Collecting: tomato_sauce\n",
            "==============================\n",
            "üîç Found 100 candidates for 'fabric contaminated with pasta sauce'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/tomato_sauce\n",
            "\n",
            "==============================\n",
            "üìå Collecting: ink\n",
            "==============================\n",
            "üîç Found 100 candidates for 'pen leak on clothing'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/ink\n",
            "\n",
            "==============================\n",
            "üìå Collecting: blood\n",
            "==============================\n",
            "üîç Found 100 candidates for 'clothing contaminated with blood marks'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/blood\n",
            "\n",
            "==============================\n",
            "üìå Collecting: chocolate\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Found 100 candidates for 'melted chocolate smudge on t-shirt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/chocolate\n",
            "\n",
            "==============================\n",
            "üìå Collecting: dirt_mud\n",
            "==============================\n",
            "üîç Found 99 candidates for 'soil marks on jeans'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/99 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/dirt_mud\n",
            "\n",
            "==============================\n",
            "üìå Collecting: juice\n",
            "==============================\n",
            "üîç Found 100 candidates for 'liquid fruit spill on cloth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/juice\n",
            "\n",
            "==============================\n",
            "üìå Collecting: coffee\n",
            "==============================\n",
            "üîç Found 100 candidates for 'spilled brewed coffee on cloth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/coffee\n",
            "\n",
            "==============================\n",
            "üìå Collecting: wine\n",
            "==============================\n",
            "üîç Found 100 candidates for 'wine soaked sleeve fabric'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 60 images ‚Üí /content/dataset/stainss/wine\n",
            "\n",
            "üéâ SerpAPI Ïù¥ÎØ∏ÏßÄ ÏàòÏßë Ï†ÑÏ≤¥ ÏôÑÎ£å!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results pillow tqdm\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from serpapi import GoogleSearch\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "SERPAPI_KEY = \"4936378b12cafdd1dc0fb613d6b8ae3dd0b866fea76df38c75658ab7c5a104b3\"\n",
        "\n",
        "classes = {\n",
        "    \"tomato_sauce\": \"fabric contaminated with pasta sauce\",\n",
        "    \"ink\": \"pen leak on clothing\",\n",
        "    \"blood\": \"clothing contaminated with blood marks\",\n",
        "    \"chocolate\": \"melted chocolate smudge on t-shirt\",\n",
        "    \"dirt_mud\": \"soil marks on jeans\",\n",
        "    \"juice\": \"liquid fruit spill on cloth\",\n",
        "    \"coffee\": \"spilled brewed coffee on cloth\",\n",
        "    \"wine\": \"wine soaked sleeve fabric\"\n",
        "}\n",
        "\n",
        "save_root = \"/content/dataset/stainss\"\n",
        "os.makedirs(save_root, exist_ok=True)\n",
        "\n",
        "def download_serpapi_images(query, folder, min_images=60):\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"tbm\": \"isch\",  # image search\n",
        "        \"ijn\": \"0\",\n",
        "        \"api_key\": SERPAPI_KEY\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "\n",
        "    if \"images_results\" not in results:\n",
        "        print(\"‚ùå No results for:\", query)\n",
        "        return\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    count = 60\n",
        "\n",
        "    print(f\"üîç Found {len(results['images_results'])} candidates for '{query}'\")\n",
        "\n",
        "    for img in tqdm(results[\"images_results\"]):\n",
        "        if count >= min_images:\n",
        "            break\n",
        "\n",
        "        url = img.get(\"original\") or img.get(\"thumbnail\")\n",
        "        if not url:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            resp = requests.get(url, timeout=15)\n",
        "            pil = Image.open(BytesIO(resp.content))\n",
        "\n",
        "            if pil.size[0] < 250 or pil.size[1] < 250:\n",
        "                continue\n",
        "\n",
        "            pil.convert(\"RGB\").save(os.path.join(folder, f\"{count}.jpg\"))\n",
        "            count += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Saved {count} images ‚Üí {folder}\")\n",
        "\n",
        "for cls, query in classes.items():\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"üìå Collecting: {cls}\")\n",
        "    print(\"==============================\")\n",
        "    folder = os.path.join(save_root, cls)\n",
        "    download_serpapi_images(query, folder, min_images=60)\n",
        "\n",
        "print(\"\\nüéâ SerpAPI Ïù¥ÎØ∏ÏßÄ ÏàòÏßë Ï†ÑÏ≤¥ ÏôÑÎ£å!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/stainss_dataset.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9oiSkO-saYa",
        "outputId": "fb6a2b88-cf4c-422f-b1de-4bdd6bdc7cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/stainss_dataset.zip\n",
            "   creating: /content/blood/\n",
            "   creating: /content/chocolate/\n",
            "   creating: /content/coffee/\n",
            "   creating: /content/dirt_mud/\n",
            "   creating: /content/ink/\n",
            "   creating: /content/juice/\n",
            "   creating: /content/tomato_sauce/\n",
            "   creating: /content/wine/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/stainss_dataset.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rtsEeOlQhqp-",
        "outputId": "c73440b8-9b5b-4ad8-ec81-41ccfd120bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_821da839-b5dc-427c-b9be-309b2c69a7ea\", \"stainss_dataset.zip\", 750)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}